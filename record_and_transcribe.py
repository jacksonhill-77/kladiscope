# record_and_transcribe.py

import sounddevice as sd
import numpy as np
import whisper
import tempfile
import scipy.io.wavfile
import time
import warnings
warnings.filterwarnings("ignore", message="FP16 is not supported on CPU*")

fs = 44100
model = None  # Global placeholder

def preload_model(model_size="base"):  # Call this from main script
    global model
    if model is None:
        print("ğŸŒ± Preloading Whisper model...")
        model = whisper.load_model(model_size)

def record_and_transcribe(seconds=5):
    global model
    print("ğŸ™ï¸ Listening...")

    # ğŸ™ï¸ RECORD AUDIO
    record_start = time.time()
    recording = sd.rec(int(seconds * fs), samplerate=fs, channels=1, dtype="int16")
    sd.wait()
    record_end = time.time()
    print(f"â±ï¸ Mic recording time: {record_end - record_start:.2f} seconds")

    # ğŸ’¾ SAVE TO TEMP FILE
    save_start = time.time()
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
        scipy.io.wavfile.write(tmpfile.name, fs, recording)
        save_end = time.time()

        # ğŸ§  TRANSCRIBE
        transcribe_start = time.time()
        result = model.transcribe(tmpfile.name)
        transcribe_end = time.time()

    print(f"â±ï¸ Save to disk time: {save_end - save_start:.2f} seconds")
    print(f"â±ï¸ Whisper transcribe time: {transcribe_end - transcribe_start:.2f} seconds")
    print(f"ğŸ—£ï¸ Transcript: {result['text'].strip()}")

    return result["text"].strip()
